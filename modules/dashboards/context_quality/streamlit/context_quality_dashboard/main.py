"""
Contextualization Quality Dashboard

Displays metrics from the pre-computed Cognite File generated by the
Contextualization Quality Metrics Cognite Function.

Tabs:
- Asset Hierarchy Quality
- Equipment‚ÄìAsset Quality  
- Time Series Contextualization
"""

import json
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from cognite.client import CogniteClient
from datetime import datetime

# ----------------------------------------------------
# PAGE CONFIG 
# ----------------------------------------------------
st.set_page_config(
    page_title="Contextualization Quality Dashboard",
    layout="wide",
    page_icon="‚≠ê"
)

# ----------------------------------------------------
# CONFIGURATION
# ----------------------------------------------------
METRICS_FILE_EXTERNAL_ID = "contextualization_quality_metrics"

# ----------------------------------------------------
# CDF CONNECTION
# ----------------------------------------------------
client = CogniteClient()

# ----------------------------------------------------
# LOAD METRICS FROM COGNITE FILE
# ----------------------------------------------------
@st.cache_data(ttl=300)  # Cache for 5 minutes
def load_metrics_from_file(external_id: str) -> dict:
    """Load pre-computed metrics from Cognite Files."""
    try:
        file_bytes = client.files.download_bytes(external_id=external_id)
        data = json.loads(file_bytes.decode("utf-8"))
        return data
    except Exception as e:
        st.error(f"Failed to load metrics file: {e}")
        return None


# ----------------------------------------------------
# UI & COLOR LOGIC 
# ----------------------------------------------------
def get_status_color_hierarchy(metric_name, value):
    if metric_name == "completion":
        if value >= 98: return "#4CAF50"
        elif value >= 95: return "#FFC107"
        else: return "#F44336"
    if metric_name == "orphans":
        if value == 0: return "#4CAF50"
        elif value <= 5: return "#FFC107"
        else: return "#F44336"
    if metric_name == "depth":
        if value <= 6: return "#4CAF50"
        elif value <= 8: return "#FFC107"
        else: return "#F44336"
    return "#0068C9"


def get_status_color_ts(metric_key, value):
    if metric_key == "association":
        if value > 80: return "#4CAF50"
        if value >= 70: return "#FFC107"
        return "#F44336"
    if metric_key == "critical_coverage":
        if value == 100: return "#4CAF50"
        if value >= 95: return "#FFC107"
        return "#F44336"
    if metric_key == "unit_consistency":
        if value > 95: return "#4CAF50"
        if value >= 90: return "#FFC107"
        return "#F44336"
    if metric_key == "gap":
        if value >= 95: return "#4CAF50"  # Higher is better (% without gaps)
        if value >= 85: return "#FFC107"
        return "#F44336"
    if metric_key == "freshness":
        if value >= 90: return "#4CAF50"
        if value >= 70: return "#FFC107"
        return "#F44336"
    return "#0068C9"


def get_status_color_equipment(metric_key, value):
    if metric_key == "association":
        if value >= 90: return "#4CAF50"
        if value >= 70: return "#FFC107"
        return "#F44336"
    if metric_key == "coverage":
        if value >= 90: return "#4CAF50"
        if value >= 70: return "#FFC107"
        return "#F44336"
    if metric_key == "serial":
        if value >= 90: return "#4CAF50"
        if value >= 70: return "#FFC107"
        return "#F44336"
    if metric_key == "manufacturer":
        if value >= 80: return "#4CAF50"
        if value >= 60: return "#FFC107"
        return "#F44336"
    if metric_key == "type_consistency":
        if value >= 95: return "#4CAF50"
        if value >= 85: return "#FFC107"
        return "#F44336"
    if metric_key == "critical":
        if value == 100: return "#4CAF50"
        if value >= 90: return "#FFC107"
        return "#F44336"
    return "#0068C9"


def metric_card(col, title, value, metric_key=None, suffix="", color_func=get_status_color_hierarchy, raw_value=None, help_text=None):
    """
    Display a styled metric card with optional help tooltip.
    
    Args:
        col: Streamlit column to render in
        title: Card title
        value: Display value (can be formatted string)
        metric_key: Key for color function lookup
        suffix: Suffix to append to value (e.g., "%")
        color_func: Function to determine color based on metric
        raw_value: Raw numeric value for color calculation (if different from display value)
        help_text: Optional tooltip text shown on hover over question mark
    """
    # Use raw_value for color calculation if provided, otherwise try to use value
    color_value = raw_value if raw_value is not None else value
    color = color_func(metric_key, color_value) if metric_key else "#0068C9"
    
    # Build title with optional help icon
    help_icon = ""
    if help_text:
        # Escape quotes in help text for HTML attribute
        escaped_help = help_text.replace('"', '&quot;').replace("'", "&#39;")
        help_icon = f"""<span title="{escaped_help}" style='cursor:help;margin-left:4px;color:#888;font-size:12px;'>‚ìò</span>"""
    
    col.markdown(f"""
    <div style='background:#F7F9FB;padding:14px;border-radius:12px;box-shadow:0 1px 4px rgba(0,0,0,0.08);border-left:6px solid {color};text-align:center;'>
        <div style='font-size:14px;color:#666;'>{title}{help_icon}</div>
        <div style='font-size:28px;font-weight:600;color:{color};'>{value}{suffix}</div>
    </div>
    """, unsafe_allow_html=True)


def gauge(col, title, value, metric_key, color_func, axis_range, suffix="%", key=None, help_text=None):
    """Display a gauge with optional help text."""
    color = color_func(metric_key, value)
    fig = go.Figure(go.Indicator(
        mode="gauge+number",
        value=value,
        title={'text': title},
        number={'suffix': suffix},
        gauge={'axis': {'range': axis_range}, 'bar': {'color': color}}
    ))
    fig.update_layout(height=300, margin=dict(l=20, r=20, t=120, b=80))
    col.plotly_chart(fig, use_container_width=True, key=key)
    
    # Show help text below the gauge if provided
    if help_text:
        col.markdown(f"<div style='text-align:center;font-size:12px;color:#666;margin-top:-15px;'>‚ìò {help_text}</div>", unsafe_allow_html=True)


def gauge_na(col, title, message="N/A", key=None, help_text=None):
    """Display a grayed-out gauge for metrics that are not applicable."""
    fig = go.Figure(go.Indicator(
        mode="gauge+number",
        value=0,
        title={'text': title},
        number={'font': {'color': '#999999'}, 'suffix': ''},
        gauge={
            'axis': {'range': [0, 100], 'tickcolor': '#cccccc'},
            'bar': {'color': '#e0e0e0'},
            'bgcolor': '#f5f5f5',
            'bordercolor': '#cccccc',
        }
    ))
    fig.update_layout(
        height=300, 
        margin=dict(l=20, r=20, t=120, b=80),
        annotations=[
            dict(
                text=message,
                x=0.5,
                y=0.25,
                showarrow=False,
                font=dict(size=14, color='#888888'),
                xref='paper',
                yref='paper'
            )
        ]
    )
    col.plotly_chart(fig, use_container_width=True, key=key)
    
    # Show help text below the gauge if provided
    if help_text:
        col.markdown(f"<div style='text-align:center;font-size:12px;color:#666;margin-top:-15px;'>‚ìò {help_text}</div>", unsafe_allow_html=True)


# ----------------------------------------------------
# DASHBOARD PAGE: ASSET HIERARCHY 
# ----------------------------------------------------
def render_asset_hierarchy_dashboard(metrics: dict):
    st.title("üå≥ Asset Hierarchy Quality Dashboard")
    
    hierarchy = metrics.get("hierarchy_metrics", {})
    metadata = metrics.get("metadata", {})
    
    if not hierarchy:
        st.warning("No hierarchy metrics found in the data file.")
        return
    
    # Show data info
    computed_at = metadata.get("computed_at", "Unknown")
    st.info(f"üìÖ Metrics computed at: {computed_at}")
    
    # Extract metrics
    total_assets = hierarchy.get("hierarchy_total_assets", 0)
    root_assets = hierarchy.get("hierarchy_root_assets", 0)
    orphan_count = hierarchy.get("hierarchy_orphan_count", 0)
    orphan_rate = hierarchy.get("hierarchy_orphan_rate", 0)
    hierarchy_completion_rate = hierarchy.get("hierarchy_completion_rate", 0)
    avg_depth = hierarchy.get("hierarchy_avg_depth", 0)
    max_depth = hierarchy.get("hierarchy_max_depth", 0)
    avg_children = hierarchy.get("hierarchy_avg_children", 0)
    std_children = hierarchy.get("hierarchy_std_children", 0)
    max_children = hierarchy.get("hierarchy_max_children", 0)
    depth_distribution = hierarchy.get("hierarchy_depth_distribution", {})
    breadth_distribution = hierarchy.get("hierarchy_breadth_distribution", {})
    
    # METRIC CARDS
    col1, col2, col3, col4 = st.columns(4)
    metric_card(col1, "Total Assets", f"{total_assets:,}",
                help_text="Total number of unique assets in the hierarchy")
    metric_card(col2, "Root Assets", f"{root_assets:,}",
                help_text="Assets at the top level with no parent (hierarchy entry points)")
    metric_card(col3, "Orphans", f"{orphan_count:,}", metric_key="orphans", 
                color_func=get_status_color_hierarchy, raw_value=orphan_count,
                help_text="Assets with no parent AND no children (disconnected from hierarchy)")
    metric_card(col4, "Orphan Rate", f"{orphan_rate:.2f}", suffix="%", 
                metric_key="orphans", color_func=get_status_color_hierarchy, raw_value=orphan_rate,
                help_text="Percentage of assets that are orphans")
    
    st.markdown("---")
    
    # GAUGE SECTION
    st.subheader("Key Structural Quality Indicators")
    g1, g2, g3 = st.columns(3)
    max_depth_range = max(max_depth, 10)
    
    gauge(g1, "Hierarchy Completion", hierarchy_completion_rate, "completion", 
          get_status_color_hierarchy, [0, 100], "%", key="h_completion",
          help_text="% of non-root assets that have a valid parent link")
    gauge(g2, "Average Depth", avg_depth, "depth", 
          get_status_color_hierarchy, [0, max_depth_range], "", key="h_avg_depth",
          help_text="Mean number of levels from root to each asset")
    gauge(g3, "Max Depth", max_depth, "depth", 
          get_status_color_hierarchy, [0, max_depth_range], "", key="h_max_depth",
          help_text="Deepest level in the hierarchy (too deep may indicate issues)")
    
    st.markdown("---")
    
    # Additional Stats
    st.subheader("Breadth Statistics")
    c1, c2, c3 = st.columns(3)
    c1.metric("Average Children per Parent", f"{avg_children:.2f}",
              help="Mean number of direct children per parent asset")
    c2.metric("Std Dev Children", f"{std_children:.2f}",
              help="Standard deviation of children count (high = uneven distribution)")
    c3.metric("Max Children", f"{max_children:,}",
              help="Maximum children under a single parent")
    
    st.markdown("---")
    
    # DISTRIBUTIONS
    st.subheader("Depth Distribution")
    st.markdown("<span style='color:#666;font-size:13px;'>‚ìò Shows how many assets exist at each level of the hierarchy. Level 0 = root assets, Level 1 = direct children of roots, etc.</span>", unsafe_allow_html=True)
    if depth_distribution:
        # Convert string keys to int for proper sorting
        depth_dist_clean = {int(k): v for k, v in depth_distribution.items()}
        depth_df = pd.DataFrame(list(depth_dist_clean.items()), columns=["Depth", "Count"])
        depth_df = depth_df.sort_values("Depth")
        fig_depth = px.bar(depth_df, x="Depth", y="Count", text="Count")
        fig_depth.update_traces(textposition='outside')
        st.plotly_chart(fig_depth, use_container_width=True)
    else:
        st.info("No depth distribution data available.")
    
    st.subheader("Breadth Distribution (Children per Parent)")
    st.markdown("<span style='color:#666;font-size:13px;'>‚ìò Shows how many parent assets have X number of children. Helps identify imbalanced hierarchies (e.g., one parent with 1000+ children).</span>", unsafe_allow_html=True)
    if breadth_distribution:
        # Convert and limit to top 20 for readability
        breadth_dist_clean = {int(k): v for k, v in breadth_distribution.items()}
        breadth_df = pd.DataFrame(list(breadth_dist_clean.items()), columns=["Children Count", "Number of Parents"])
        breadth_df = breadth_df.sort_values("Children Count").head(30)
        fig_breadth = px.bar(breadth_df, x="Children Count", y="Number of Parents", text="Number of Parents")
        fig_breadth.update_traces(textposition='outside')
        st.plotly_chart(fig_breadth, use_container_width=True)
    else:
        st.info("No breadth distribution data available.")
    
    st.markdown("---")
    st.success("‚úÖ Asset Hierarchy dashboard loaded from pre-computed metrics.")


# ----------------------------------------------------
# DASHBOARD PAGE: EQUIPMENT-ASSET RELATIONSHIP QUALITY
# ----------------------------------------------------
def render_equipment_dashboard(metrics: dict):
    st.title("üîß Equipment‚ÄìAsset Relationship Quality Dashboard")
    
    equipment = metrics.get("equipment_metrics", {})
    metadata = metrics.get("metadata", {})
    
    if not equipment:
        st.warning("No equipment metrics found in the data file.")
        return
    
    # Show data info
    computed_at = metadata.get("computed_at", "Unknown")
    st.info(f"üìÖ Metrics computed at: {computed_at}")
    
    # Extract metrics
    total_equipment = equipment.get("eq_total", 0)
    association_rate = equipment.get("eq_association_rate", 0)
    linked_eq = equipment.get("eq_linked", 0)
    unlinked_eq = equipment.get("eq_unlinked", 0)
    asset_coverage = equipment.get("eq_asset_coverage", 0)
    assets_with_eq = equipment.get("eq_assets_with_equipment", 0)
    serial_rate = equipment.get("eq_serial_completeness", 0)
    manufacturer_rate = equipment.get("eq_manufacturer_completeness", 0)
    type_consistency_rate = equipment.get("eq_type_consistency_rate", 0)
    critical_rate = equipment.get("eq_critical_contextualization")  # Can be None
    critical_total = equipment.get("eq_critical_total", 0)
    critical_linked = equipment.get("eq_critical_linked", 0)
    has_critical_equipment = equipment.get("eq_has_critical_equipment", False)
    avg_eq_per_asset = equipment.get("eq_avg_per_asset", 0)
    max_eq_per_asset = equipment.get("eq_max_per_asset", 0)
    
    # Summary cards
    col1, col2, col3, col4 = st.columns(4)
    metric_card(col1, "Total Equipment", f"{total_equipment:,}",
                help_text="Total number of unique equipment items")
    metric_card(col2, "Linked Equipment", f"{linked_eq:,}",
                help_text="Equipment items that have a valid asset link")
    metric_card(col3, "Unlinked Equipment", f"{unlinked_eq:,}",
                help_text="Equipment items missing an asset link (need contextualization)")
    metric_card(col4, "Assets with Equipment", f"{assets_with_eq:,}",
                help_text="Number of assets that have at least one equipment linked")
    
    st.markdown("---")
    
    # GAUGES ‚Äì ALL % METRICS
    g1, g2, g3 = st.columns(3)
    gauge(g1, "Equipment Association", association_rate, "association", 
          get_status_color_equipment, [0, 100], "%", key="eq_assoc",
          help_text="% of equipment linked to an asset")
    gauge(g2, "Asset Equipment Coverage", asset_coverage, "coverage", 
          get_status_color_equipment, [0, 100], "%", key="eq_coverage",
          help_text="% of assets that have equipment linked to them")
    gauge(g3, "Serial Number Completeness", serial_rate, "serial", 
          get_status_color_equipment, [0, 100], "%", key="eq_serial",
          help_text="% of equipment with serial number populated")
    
    st.write("")
    
    g4, g5, g6 = st.columns(3)
    gauge(g4, "Manufacturer Data Quality", manufacturer_rate, "manufacturer", 
          get_status_color_equipment, [0, 100], "%", key="eq_manu",
          help_text="% of equipment with manufacturer info populated")
    gauge(g5, "Type Consistency", type_consistency_rate, "type_consistency", 
          get_status_color_equipment, [0, 100], "%", key="eq_type",
          help_text="% of equipment where type matches linked asset type")
    
    # Critical Equipment - show N/A if no critical equipment is defined
    if has_critical_equipment and critical_rate is not None:
        gauge(g6, "Critical Equipment", critical_rate, "critical", 
              get_status_color_equipment, [0, 100], "%", key="eq_critical",
              help_text="% of critical equipment linked to an asset (should be 100%)")
    else:
        gauge_na(g6, "Critical Equipment", "No critical equipment defined", key="eq_critical_na",
                 help_text="% of critical equipment linked to an asset")
    
    st.markdown("---")
    
    # Additional Stats
    st.subheader("üìä Equipment Distribution")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("Avg Equipment per Asset", f"{avg_eq_per_asset:.2f}",
              help="Average number of equipment items per asset")
    c2.metric("Max Equipment per Asset", f"{max_eq_per_asset:,}",
              help="Maximum equipment linked to a single asset")
    c3.metric("Critical Equipment Total", f"{critical_total:,}",
              help="Equipment items marked as critical")
    c4.metric("Critical Equipment Linked", f"{critical_linked:,}",
              help="Critical equipment with valid asset links")
    
    st.markdown("---")
    
    # Summary
    if unlinked_eq == 0:
        st.success("üéâ All equipment is properly linked to assets!")
    else:
        st.warning(f"‚ö†Ô∏è {unlinked_eq:,} equipment items are missing asset links.")
    
    st.markdown("---")
    st.success("‚úÖ Equipment‚ÄìAsset dashboard loaded from pre-computed metrics.")


# ----------------------------------------------------
# DASHBOARD PAGE: TIME SERIES CONTEXTUALIZATION 
# ----------------------------------------------------
def render_time_series_dashboard(metrics: dict):
    st.title("‚è±Ô∏è Time Series Contextualization Quality Dashboard")
    
    ts_metrics = metrics.get("timeseries_metrics", {})
    hierarchy = metrics.get("hierarchy_metrics", {})
    metadata = metrics.get("metadata", {})
    
    if not ts_metrics:
        st.warning("No time series metrics found in the data file.")
        return
    
    # Show data info
    computed_at = metadata.get("computed_at", "Unknown")
    st.info(f"üìÖ Metrics computed at: {computed_at}")
    
    st.markdown("---")
    
    # Extract metrics
    association_rate = ts_metrics.get("ts_association_rate", 0)
    associated_assets = ts_metrics.get("ts_associated_assets", 0)
    critical_coverage = ts_metrics.get("ts_critical_coverage")  # Can be None
    critical_with_ts = ts_metrics.get("ts_critical_with_ts", 0)
    critical_total = ts_metrics.get("ts_critical_total", 0)
    has_critical_assets = ts_metrics.get("ts_has_critical_assets", False)
    # Unit metrics
    source_unit_completeness = ts_metrics.get("ts_source_unit_completeness", 0)
    target_unit_completeness = ts_metrics.get("ts_target_unit_completeness", 0)
    any_unit_completeness = ts_metrics.get("ts_any_unit_completeness", 0)
    unit_mapping_rate = ts_metrics.get("ts_unit_mapping_rate")  # Can be None
    has_source_unit = ts_metrics.get("ts_has_source_unit", 0)
    has_target_unit = ts_metrics.get("ts_has_target_unit", 0)
    has_any_unit = ts_metrics.get("ts_has_any_unit", 0)
    units_match = ts_metrics.get("ts_units_match", 0)
    unit_checks = ts_metrics.get("ts_unit_checks", 0)
    unique_source_units = ts_metrics.get("ts_unique_source_units", 0)
    # Historical Data Completeness metrics
    historical_data_completeness = ts_metrics.get("ts_historical_data_completeness")  # Can be None
    ts_analyzed_for_gaps = ts_metrics.get("ts_analyzed_for_gaps", 0)
    total_time_span_days = ts_metrics.get("ts_total_time_span_days", 0)
    total_gap_duration_days = ts_metrics.get("ts_total_gap_duration_days", 0)
    gap_count = ts_metrics.get("ts_gap_count", 0)
    longest_gap_days = ts_metrics.get("ts_longest_gap_days", 0)
    avg_gap_days = ts_metrics.get("ts_avg_gap_days", 0)
    # Other metrics
    data_freshness = ts_metrics.get("ts_data_freshness", 0)
    fresh_count = ts_metrics.get("ts_fresh_count", 0)
    processing_lag_hours = ts_metrics.get("ts_processing_lag_hours")
    total_ts = ts_metrics.get("ts_total", 0)
    total_assets = hierarchy.get("hierarchy_total_assets", 0)
    
    # Summary cards
    col1, col2, col3, col4 = st.columns(4)
    metric_card(col1, "Total Time Series", f"{total_ts:,}",
                help_text="Total number of unique time series")
    metric_card(col2, "Total Assets", f"{total_assets:,}",
                help_text="Total assets available for time series linking")
    metric_card(col3, "Assets with TS", f"{associated_assets:,}",
                help_text="Number of assets that have at least one time series linked")
    metric_card(col4, "Fresh TS (30 days)", f"{fresh_count:,}",
                help_text="Time series updated within the last 30 days")
    
    st.markdown("---")
    
    st.header("üìä Data Quality Metrics")
    
    # METRIC CARDS (GAUGES) - Row 1
    g1, g2, g3 = st.columns(3)
    gauge(g1, "Asset TS Association", association_rate, "association", 
          get_status_color_ts, [0, 100], "%", key="ts_assoc",
          help_text="% of assets that have at least one time series linked")
    
    # Critical Asset Coverage - show N/A if no critical assets defined
    if has_critical_assets and critical_coverage is not None:
        gauge(g2, "Critical Asset Coverage", critical_coverage, "critical_coverage", 
              get_status_color_ts, [0, 100], "%", key="ts_critical",
              help_text="% of critical assets with time series (should be 100%)")
    else:
        gauge_na(g2, "Critical Asset Coverage", "No critical assets defined", key="ts_critical_na",
                 help_text="% of critical assets with time series linked")
    
    # Source Unit Completeness (primary unit metric since sourceUnit has data)
    gauge(g3, "Source Unit Completeness", source_unit_completeness, "unit_consistency", 
          get_status_color_ts, [0, 100], "%", key="ts_src_unit",
          help_text="% of time series with sourceUnit populated (e.g., ¬∞C, mm, %)")
    
    st.markdown("---")
    
    # Row 2: Freshness, Historical Completeness, Target Unit
    g4, g5, g6 = st.columns(3)
    gauge(g4, "Data Freshness (Last 30 Days)", data_freshness, "freshness", 
          get_status_color_ts, [0, 100], "%", key="ts_fresh",
          help_text="% of time series updated within the last 30 days")
    
    # Historical Data Completeness - show N/A if not analyzed
    if historical_data_completeness is not None and ts_analyzed_for_gaps > 0:
        gauge(g5, "Historical Data Completeness", historical_data_completeness, "gap", 
              get_status_color_ts, [0, 100], "%", key="ts_gap",
              help_text="% of time span with actual data (100% - gap duration)")
    else:
        gauge_na(g5, "Historical Data Completeness", "Enable in config to analyze", key="ts_gap_na",
                 help_text="Detects gaps >7 days in historical data")
    
    # Target Unit Completeness (standardized unit)
    if target_unit_completeness > 0:
        gauge(g6, "Target Unit (Standardized)", target_unit_completeness, "unit_consistency", 
              get_status_color_ts, [0, 100], "%", key="ts_tgt_unit",
              help_text="% of time series with standardized unit populated")
    else:
        gauge_na(g6, "Target Unit (Standardized)", "No standardized units defined", key="ts_tgt_unit_na",
                 help_text="% of time series with standardized unit populated")
    
    st.markdown("---")
    
    # DIAGNOSTICS & LAG
    st.subheader("‚è±Ô∏è Diagnostics")
    c1, c2 = st.columns(2)
    
    if processing_lag_hours is not None:
        c1.metric(
            "Average Processing Lag",
            f"{processing_lag_hours:.2f} hours",
            help="Average time difference between 'now' and the Time Series' lastUpdatedTime."
        )
    else:
        c1.metric("Average Processing Lag", "N/A")
    
    # Data Breakdown
    c2.markdown("### Data Breakdown")
    c2.markdown(f"""
    | Metric | Value |
    |--------|-------|
    | Total Assets | {total_assets:,} |
    | Assets with TS | {associated_assets:,} |
    | Total Critical Assets | {critical_total:,} |
    | Critical Assets with TS | {critical_with_ts:,} |
    | TS with Source Unit | {has_source_unit:,} |
    | TS with Target Unit | {has_target_unit:,} |
    | Unique Source Units | {unique_source_units:,} |
    | Fresh TS Count | {fresh_count:,} |
    """)
    
    # Historical Data Completeness Details
    if ts_analyzed_for_gaps > 0:
        st.markdown("---")
        st.subheader("üìä Historical Data Completeness Analysis")
        st.markdown(f"""
        Analyzed **{ts_analyzed_for_gaps:,}** time series for significant data gaps (>{7} days without data).
        """)
        
        d1, d2, d3, d4 = st.columns(4)
        d1.metric("Total Time Span", f"{total_time_span_days:,.0f} days", 
                  help="Sum of time spans (first to last datapoint) across all analyzed TS")
        d2.metric("Gaps Found", f"{gap_count:,}",
                  help="Number of periods > 7 days without data")
        d3.metric("Total Gap Duration", f"{total_gap_duration_days:,.0f} days",
                  help="Sum of all gap durations")
        d4.metric("Longest Gap", f"{longest_gap_days:,.0f} days",
                  help="Duration of the longest gap found")
        
        if gap_count > 0:
            st.warning(f"""
            ‚ö†Ô∏è **Gap Summary:** Found {gap_count:,} significant gaps totaling {total_gap_duration_days:,.0f} days. 
            Average gap duration: {avg_gap_days:.1f} days. Longest gap: {longest_gap_days:.0f} days.
            """)
        else:
            st.success("‚úÖ No significant data gaps (>7 days) detected in the analyzed time series.")
    
    st.markdown("---")
    st.success("‚úÖ Time Series Contextualization dashboard loaded from pre-computed metrics.")


# ----------------------------------------------------
# METADATA DISPLAY
# ----------------------------------------------------
def render_metadata_sidebar(metrics: dict):
    """Display metadata in the sidebar."""
    metadata = metrics.get("metadata", {})
    
    st.sidebar.title("üìã Metrics Info")
    
    computed_at = metadata.get("computed_at", "Unknown")
    if computed_at != "Unknown":
        try:
            dt = datetime.fromisoformat(computed_at.replace("Z", "+00:00"))
            computed_at = dt.strftime("%Y-%m-%d %H:%M:%S UTC")
        except:
            pass
    
    st.sidebar.markdown(f"**Computed At:** {computed_at}")
    
    execution_time = metadata.get("execution_time_seconds", 0)
    st.sidebar.markdown(f"**Execution Time:** {execution_time:.1f}s")
    
    st.sidebar.markdown("---")
    
    # Instance Counts Section
    st.sidebar.markdown("### üìä Instance Counts")
    instance_counts = metadata.get("instance_counts", {})
    
    # Assets
    asset_counts = instance_counts.get("assets", {})
    asset_total = asset_counts.get("total_instances", 0)
    asset_unique = asset_counts.get("unique", 0)
    asset_dups = asset_counts.get("duplicates", 0)
    
    st.sidebar.markdown("**Assets:**")
    st.sidebar.markdown(f"- Total Instances: {asset_total:,}")
    st.sidebar.markdown(f"- Unique: {asset_unique:,}")
    if asset_dups > 0:
        st.sidebar.markdown(f"- ‚ö†Ô∏è Duplicates: {asset_dups:,}")
    else:
        st.sidebar.markdown(f"- Duplicates: {asset_dups:,}")
    
    # Equipment
    eq_counts = instance_counts.get("equipment", {})
    eq_total = eq_counts.get("total_instances", 0)
    eq_unique = eq_counts.get("unique", 0)
    eq_dups = eq_counts.get("duplicates", 0)
    
    st.sidebar.markdown("**Equipment:**")
    st.sidebar.markdown(f"- Total Instances: {eq_total:,}")
    st.sidebar.markdown(f"- Unique: {eq_unique:,}")
    if eq_dups > 0:
        st.sidebar.markdown(f"- ‚ö†Ô∏è Duplicates: {eq_dups:,}")
    else:
        st.sidebar.markdown(f"- Duplicates: {eq_dups:,}")
    
    # Time Series
    ts_counts = instance_counts.get("timeseries", {})
    ts_total = ts_counts.get("total_instances", 0)
    ts_unique = ts_counts.get("unique", 0)
    ts_dups = ts_counts.get("duplicates", 0)
    
    st.sidebar.markdown("**Time Series:**")
    st.sidebar.markdown(f"- Total Instances: {ts_total:,}")
    st.sidebar.markdown(f"- Unique: {ts_unique:,}")
    if ts_dups > 0:
        st.sidebar.markdown(f"- ‚ö†Ô∏è Duplicates: {ts_dups:,}")
    else:
        st.sidebar.markdown(f"- Duplicates: {ts_dups:,}")
    
    st.sidebar.markdown("---")
    st.sidebar.markdown("### Batches Processed")
    batches = metadata.get("batches_processed", {})
    st.sidebar.markdown(f"- Assets: {batches.get('assets', 0):,}")
    st.sidebar.markdown(f"- Equipment: {batches.get('equipment', 0):,}")
    st.sidebar.markdown(f"- Time Series: {batches.get('ts', 0):,}")
    
    st.sidebar.markdown("---")
    st.sidebar.markdown("### üìä Processing Coverage")
    config = metadata.get("config", {})
    limits = metadata.get("limits_reached", {})
    
    # Get actual processed counts
    ts_processed = ts_unique
    asset_processed = asset_unique
    eq_processed = eq_unique
    
    ts_limit = config.get("max_timeseries", 150000)
    asset_limit = config.get("max_assets", 150000)
    eq_limit = config.get("max_equipment", 150000)
    
    ts_limit_reached = limits.get("timeseries", False)
    asset_limit_reached = limits.get("assets", False)
    eq_limit_reached = limits.get("equipment", False)
    
    any_limit_reached = ts_limit_reached or asset_limit_reached or eq_limit_reached
    
    # Assets
    if asset_limit_reached:
        st.sidebar.markdown(f"**Assets:** {asset_processed:,} of {asset_limit:,} limit ‚ö†Ô∏è LIMIT REACHED")
    else:
        st.sidebar.markdown(f"**Assets:** {asset_processed:,} ‚úÖ All processed")
    
    # Equipment
    if eq_limit_reached:
        st.sidebar.markdown(f"**Equipment:** {eq_processed:,} of {eq_limit:,} limit ‚ö†Ô∏è LIMIT REACHED")
    else:
        st.sidebar.markdown(f"**Equipment:** {eq_processed:,} ‚úÖ All processed")
    
    # Time Series
    if ts_limit_reached:
        st.sidebar.markdown(f"**Time Series:** {ts_processed:,} of {ts_limit:,} limit ‚ö†Ô∏è LIMIT REACHED")
    else:
        st.sidebar.markdown(f"**Time Series:** {ts_processed:,} ‚úÖ All processed")
    
    # Warning if any limit was reached
    if any_limit_reached:
        st.sidebar.markdown("---")
        st.sidebar.warning("""
        ‚ö†Ô∏è **Partial Data Warning**
        
        One or more processing limits were reached. The metrics shown represent **trends only** and do not reflect the complete dataset.
        
        To analyze all data, increase the limits in the function configuration. 

        Note: Higher limits may cause function timeouts (max 10 min).
        """)
    
    st.sidebar.markdown("---")
    if st.sidebar.button("üîÑ Refresh Data"):
        st.cache_data.clear()
        st.rerun()


# ----------------------------------------------------
# MAIN APP EXECUTION
# ----------------------------------------------------
st.title("‚≠ê Contextualization Quality Dashboard")
st.write("Displays pre-computed metrics from the Contextualization Function.")
st.markdown("---")

# Load metrics from Cognite File
with st.spinner("Loading metrics from Cognite Files..."):
    metrics = load_metrics_from_file(METRICS_FILE_EXTERNAL_ID)

if metrics is None:
    st.error(f"""
    ‚ùå **Could not load metrics file**
    
    Please ensure the Contextualization Quality Metrics Function has been run 
    and the file `{METRICS_FILE_EXTERNAL_ID}` exists in Cognite Files.
    
    """)
    st.stop()

# Render sidebar with metadata
render_metadata_sidebar(metrics)

# Tab navigation
tab_asset, tab_equipment, tab_ts = st.tabs([
    "üå≥ Asset Hierarchy Quality",
    "üîß Equipment‚ÄìAsset Quality",
    "‚è±Ô∏è Time Series Contextualization"
])

with tab_asset:
    render_asset_hierarchy_dashboard(metrics)

with tab_equipment:
    render_equipment_dashboard(metrics)

with tab_ts:
    render_time_series_dashboard(metrics)

