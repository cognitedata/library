# Context Quality Metrics - Local Script

This folder contains a local script for running the context quality metrics collection on your local machine instead of using Cognite Functions.

## Advantages over Cognite Functions

- **No timeout limits** - Can run for hours if needed (no 10-minute limit)
- **More resources** - Uses your laptop's CPU and memory
- **Easier debugging** - Local breakpoints, logging, error messages
- **No deployment required** - Just run the script
- **Simpler architecture** - No batch processing complexity

## Prerequisites

1. Python 3.9+
2. Access to a CDF project
3. Valid authentication credentials

## Installation

```bash
# Navigate to the scripts folder
cd templates/modules/solutions/context_quality/scripts

# Create a virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

## Authentication

The script supports multiple authentication methods and uses the same environment variable names as `cognite-toolkit`.

### Option 1: Use existing .env file (Recommended)

If you have a `.env` file from cognite-toolkit, the script will use it automatically:

```bash
# .env file (generated by cognite-toolkit)
CDF_CLUSTER=aws-dub-dev
CDF_PROJECT=templates-dev
IDP_CLIENT_ID=your-client-id
IDP_CLIENT_SECRET=your-client-secret
IDP_TENANT_ID=your-azure-tenant-id
IDP_TOKEN_URL=https://login.microsoftonline.com/{tenant}/oauth2/v2.0/token
IDP_SCOPES=https://aws-dub-dev.cognitedata.com/.default
```

### Option 2: Direct Token

```bash
export CDF_PROJECT="your-project-name"
export CDF_CLUSTER="westeurope-1"  # or your cluster
export CDF_TOKEN="your-bearer-token"
```

You can get a token from:
- Fusion UI: Account Settings > Manage tokens
- Azure CLI: `az account get-access-token --resource https://westeurope-1.cognitedata.com`

### Option 3: OAuth Client Credentials

```bash
export CDF_PROJECT="your-project-name"
export CDF_CLUSTER="westeurope-1"
export IDP_CLIENT_ID="your-client-id"
export IDP_CLIENT_SECRET="your-client-secret"
export IDP_TENANT_ID="your-azure-tenant-id"
```

### Option 4: Cognite Toolkit Integration

If you have `cognite-toolkit` configured, the script will automatically use those credentials.

## Usage

### Basic Usage

```bash
# Run with default settings
python run_metrics.py

# View help
python run_metrics.py --help
```

### Command Syntax

**All options can be freely combined in any order.** Simply add multiple flags to a single command:

```bash
python run_metrics.py [OPTIONS...]
```

**General pattern:**
```bash
python run_metrics.py \
  --<view-option> "space/view_id/version" \
  --<feature-toggle> \
  --<limit-option> <number> \
  --<output-option>
```

**Quick example - combining views with performance flags:**
```bash
# Use custom views
python run_metrics.py --ts-view "rmdm/MyTimeSeries/v1" --asset-view "rmdm/MyAsset/v1"
```

---

### All Options Reference

| Option | Type | Description |
|--------|------|-------------|
| **View Configuration** |||
| `--ts-view` | `SPACE/VIEW/VERSION` | Custom Time Series view |
| `--asset-view` | `SPACE/VIEW/VERSION` | Custom Asset view |
| `--equipment-view` | `SPACE/VIEW/VERSION` | Custom Equipment view |
| `--file-view` | `SPACE/VIEW/VERSION` | Custom File view |
| `--notification-view` | `SPACE/VIEW/VERSION` | Custom Notification view |
| `--order-view` | `SPACE/VIEW/VERSION` | Custom Maintenance Order view |
| `--annotation-view` | `SPACE/VIEW/VERSION` | Custom Annotation view |
| `--3d-view` | `SPACE/VIEW/VERSION` | Custom 3D Object view |
| **Instance Limits** |||
| `--max-ts` | number | Max time series to process |
| `--max-assets` | number | Max assets to process |
| `--max-equipment` | number | Max equipment to process |
| `--max-notifications` | number | Max notifications to process |
| `--max-orders` | number | Max maintenance orders to process |
| `--max-annotations` | number | Max annotations to process |
| `--max-3d` | number | Max 3D objects to process |
| `--max-files` | number | Max files to process |
| **Selective Recompute** |||
| `--only <section>` | string | Only recompute specific section(s), preserve others from cache |
| **Staging Configuration** |||
| `--staging-db` | string | Raw database for staging (default: oracle:db) |
| `--staging-space` | string | DM space for staging (default: rmdm) |
| `--staging-version` | string | DM version for staging (default: v1) |
| **Output** |||
| `--dry-run` | flag | Save locally, don't upload to CDF |
| `--output-file` | path | Custom output file path |
| `-v`, `--verbose` | flag | Enable verbose logging |

---

### Custom Limits

```bash
# Process fewer instances (faster for testing)
python run_metrics.py --max-ts 10000 --max-assets 5000

# Process more instances
python run_metrics.py --max-ts 1000000 --max-assets 500000
```


### Custom View Configuration

By default, the script uses CDM views (`cdf_cdm/CogniteTimeSeries/v1`, etc.). You can override these to use your own data model views.

**Format:** `--<type>-view "space/view_id/version"`

```bash
# Use custom views for time series and assets
python run_metrics.py \
  --ts-view "rmdm/YourOrgTimeSeries/v1" \
  --asset-view "rmdm/YourOrgAsset/v1"

# Configure multiple custom views
python run_metrics.py \
  --ts-view "my_space/MyTimeSeries/v1" \
  --asset-view "my_space/MyAsset/v1" \
  --equipment-view "my_space/MyEquipment/v1" \
  --file-view "my_space/MyFile/v1"

# Available view flags:
#   --ts-view           Time Series view
#   --asset-view        Asset view
#   --equipment-view    Equipment view
#   --file-view         File view
#   --notification-view Notification view
#   --order-view        Maintenance Order view
#   --annotation-view   Annotation view
#   --3d-view           3D Object view
```

### Selective Recompute

When iterating on a specific tab/section, you can recompute only that section while preserving others from cache.

```bash
# Only recompute staging, preserve all other tabs from cache
python run_metrics.py --only staging

# Only recompute assets, preserve others
python run_metrics.py --only assets

# Recompute multiple sections
python run_metrics.py --only assets --only equipment

# Recompute time series only
python run_metrics.py --only ts

# Available sections for --only:
#   ts, assets, equipment, maintenance, annotations, 3d, files, staging
```

**How it works:**
1. Downloads previous metrics file from CDF
2. Runs only the specified sections
3. Merges new results with cached data for other sections
4. Uploads the combined result

This is useful when:
- Testing changes to a specific data type
- Debugging issues with one metric category
- Refreshing stale data for one section
- Running only staging comparison without affecting other metrics

### Combining Multiple Options

All command-line options can be combined freely. Here are common combinations:

#### Custom Views + Performance Options

```bash
# Use custom views
python run_metrics.py \
  --ts-view "rmdm/YourOrgTimeSeries/v1" \
  --asset-view "rmdm/YourOrgAsset/v1"

# Full custom data model with limits
python run_metrics.py \
  --ts-view "rmdm/OrgTimeSeries/v1" \
  --asset-view "rmdm/OrgAsset/v1" \
  --equipment-view "rmdm/OrgEquipment/v1" \
  --file-view "rmdm/OrgFile/v1" \
  --notification-view "rmdm/OrgNotification/v1" \
  --order-view "rmdm/OrgOrder/v1" \
  --max-ts 50000 \
  --max-assets 25000
```

#### Custom Views + Selective Recompute

```bash
# Recompute only assets with custom asset view
python run_metrics.py \
  --asset-view "my_space/MyAsset/v1" \
  --only assets

# Recompute time series with custom view
python run_metrics.py \
  --ts-view "my_space/MyTimeSeries/v1" \
  --only ts

# Refresh multiple sections with custom views
python run_metrics.py \
  --ts-view "rmdm/OrgTimeSeries/v1" \
  --equipment-view "rmdm/OrgEquipment/v1" \
  --only ts \
  --only equipment

# Only recompute staging comparison
python run_metrics.py --only staging

# Recompute staging with custom configuration
python run_metrics.py \
  --only staging \
  --staging-db "my_database" \
  --staging-space "my_space" \
  --staging-version "v2"
```

#### Testing and Development

```bash
# Quick test with custom views (small dataset, no upload)
python run_metrics.py \
  --ts-view "my_space/MyTimeSeries/v1" \
  --asset-view "my_space/MyAsset/v1" \
  --max-ts 1000 \
  --max-assets 500 \
  --dry-run \
  -v

# Fast iteration: test one section with verbose output
python run_metrics.py \
  --equipment-view "my_space/MyEquipment/v1" \
  --only equipment \
  --dry-run \
  -v

# Full pipeline test with limited data
python run_metrics.py \
  --ts-view "rmdm/OrgTimeSeries/v1" \
  --asset-view "rmdm/OrgAsset/v1" \
  --equipment-view "rmdm/OrgEquipment/v1" \
  --max-ts 5000 \
  --max-assets 2000 \
  --dry-run
```

#### Production Runs

```bash
# Full production run with custom data model (computes ALL sections)
python run_metrics.py \
  --ts-view "rmdm/OrgTimeSeries/v1" \
  --asset-view "rmdm/OrgAsset/v1" \
  --equipment-view "rmdm/OrgEquipment/v1" \
  --file-view "rmdm/OrgFile/v1" \
  --notification-view "rmdm/OrgNotification/v1" \
  --order-view "rmdm/OrgOrder/v1" \
  --annotation-view "rmdm/OrgAnnotation/v1" \
  --3d-view "rmdm/Org3DObject/v1"

# Production run with performance optimization
python run_metrics.py \
  --ts-view "rmdm/OrgTimeSeries/v1" \
  --asset-view "rmdm/OrgAsset/v1" \
  --equipment-view "rmdm/OrgEquipment/v1" \
  --max-ts 500000 \
  --max-assets 200000

# Incremental update: refresh only changed sections
python run_metrics.py \
  --ts-view "rmdm/OrgTimeSeries/v1" \
  --only ts \
  --only assets
```

#### Quick Reference: Option Categories

| Category | Options | Can Combine With |
|----------|---------|------------------|
| **Views** | `--ts-view`, `--asset-view`, `--equipment-view`, `--file-view`, `--notification-view`, `--order-view`, `--annotation-view`, `--3d-view` | All options |
| **Limits** | `--max-ts`, `--max-assets`, `--max-equipment`, `--max-notifications`, `--max-orders`, `--max-annotations`, `--max-3d`, `--max-files` | All options |
| **Selective** | `--only <section>` (ts, assets, equipment, maintenance, annotations, 3d, files, staging) | All options |
| **Staging** | `--staging-db`, `--staging-space`, `--staging-version` | All options |
| **Output** | `--dry-run`, `--output-file`, `-v` | All options |

---

### Common Questions (FAQ)

**Q: How do I set limits AND use custom views?**
```bash
python run_metrics.py \
  --ts-view "my_space/MyTS/v1" \
  --asset-view "my_space/MyAsset/v1" \
  --max-ts 10000 \
  --max-assets 5000
```

**Q: How do I recompute only specific sections with custom views?**
```bash
# Recompute only time series using custom view, reuse cached results for everything else
python run_metrics.py \
  --ts-view "my_space/MyTS/v1" \
  --only ts
```

**Q: How do I run a quick test?**
```bash
python run_metrics.py \
  --ts-view "my_space/MyTS/v1" \
  --asset-view "my_space/MyAsset/v1" \
  --max-ts 1000 \
  --max-assets 500 \
  --dry-run \
  -v
```

**Q: How do I use multiple `--only` flags together?**
```bash
# Recompute ts, assets, and equipment - keep everything else from cache
python run_metrics.py --only ts --only assets --only equipment
```

**Q: How do I recompute only staging?**
```bash
# Only run staging comparison, preserve all other metrics from cache
python run_metrics.py --only staging
```

**Q: Can I specify a custom output file with other options?**
```bash
python run_metrics.py \
  --ts-view "my_space/MyTS/v1" \
  --dry-run \
  --output-file "./my_custom_output.json"
```

**Q: What's the fastest possible run for testing?**
```bash
python run_metrics.py \
  --only ts \
  --max-ts 100 \
  --dry-run
```

---

### Dry Run (Don't Upload)

```bash
# Save results locally instead of uploading to CDF
python run_metrics.py --dry-run

# Results saved to: scripts/metrics_output.json
```

### Verbose Logging

```bash
python run_metrics.py -v
```

## Output

The script produces:
1. **Console logs** - Progress updates during execution
2. **CDF File** - JSON metrics file uploaded to CDF (same format as Cognite Function)
3. **Local file** - (dry-run only) JSON file saved locally

The Streamlit dashboard can read the output file regardless of whether it was generated by the Cognite Function or this local script.

## Troubleshooting

### Authentication Errors

```
ValueError: COGNITE_PROJECT environment variable is required
```
- Set the `COGNITE_PROJECT` environment variable

```
Failed to authenticate: 401 Unauthorized
```
- Check your token is valid and not expired
- Verify you have access to the project

### Import Errors

```
ModuleNotFoundError: No module named 'metrics'
```
- Make sure you're running from the `scripts/` directory
- The script automatically adds the metrics module to the path

### Timeout/Memory Errors

If you run into memory issues with very large datasets:
- Use `--max-*` flags to limit the number of instances
- Process in smaller batches by running multiple times with different limits

## Architecture

```
scripts/
    client.py          # CDF authentication
    run_metrics.py     # Main script
    requirements.txt   # Dependencies
    README.md          # This file

functions/context_quality_handler/
    metrics/           # Shared processing modules (used by both)
        common.py
        timeseries.py
        asset_hierarchy.py
        equipment.py
        maintenance.py
        file_annotation.py
        model_3d.py
        files.py
        storage.py
```

The local script imports and reuses the same `metrics/` modules as the Cognite Function, ensuring consistent behavior.
