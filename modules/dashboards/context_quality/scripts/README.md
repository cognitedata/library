# Context Quality Metrics - Local Script

This folder contains a local script for running the context quality metrics collection on your local machine instead of using Cognite Functions.

## Advantages over Cognite Functions

- **No timeout limits** - Can run for hours if needed (no 10-minute limit)
- **More resources** - Uses your laptop's CPU and memory
- **Easier debugging** - Local breakpoints, logging, error messages
- **No deployment required** - Just run the script
- **Simpler architecture** - No batch processing complexity

## Prerequisites

1. Python 3.9+
2. Access to a CDF project
3. Valid authentication credentials

## Installation

```bash
# Navigate to the scripts folder
cd modules/dashboards/context_quality/scripts

# Create a virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

## Authentication

The script supports multiple authentication methods and uses the same environment variable names as `cognite-toolkit`.

### Option 1: Use existing .env file (Recommended)

If you have a `.env` file from cognite-toolkit, the script will use it automatically:

```bash
# .env file (generated by cognite-toolkit)
CDF_CLUSTER=aws-dub-dev
CDF_PROJECT=templates-dev
IDP_CLIENT_ID=your-client-id
IDP_CLIENT_SECRET=your-client-secret
IDP_TENANT_ID=your-azure-tenant-id
IDP_TOKEN_URL=https://login.microsoftonline.com/{tenant}/oauth2/v2.0/token
IDP_SCOPES=https://aws-dub-dev.cognitedata.com/.default
```

### Option 2: Direct Token

```bash
export CDF_PROJECT="your-project-name"
export CDF_CLUSTER="westeurope-1"  # or your cluster
export CDF_TOKEN="your-bearer-token"
```

You can get a token from:

- Fusion UI: Account Settings > Manage tokens
- Azure CLI: `az account get-access-token --resource https://westeurope-1.cognitedata.com`

### Option 3: OAuth Client Credentials

```bash
export CDF_PROJECT="your-project-name"
export CDF_CLUSTER="westeurope-1"
export IDP_CLIENT_ID="your-client-id"
export IDP_CLIENT_SECRET="your-client-secret"
export IDP_TENANT_ID="your-azure-tenant-id"
```

### Option 4: Cognite Toolkit Integration

If you have `cognite-toolkit` configured, the script will automatically use those credentials.

## Usage

### Basic Usage

```bash
# Run with default settings
python run_metrics.py

# View help
python run_metrics.py --help
```

### Command Syntax

**All options can be freely combined in any order.** Simply add multiple flags to a single command:

```bash
python run_metrics.py [OPTIONS...]
```

**General pattern:**

```bash
python run_metrics.py \
  --<view-option> "space/view_id/version" \
  --<feature-toggle> \
  --<limit-option> <number> \
  --<output-option>
```

**Quick example - combining views with performance flags:**

```bash
# Use custom views AND skip gap analysis
python run_metrics.py --ts-view "rmdm/MyTimeSeries/v1" --asset-view "rmdm/MyAsset/v1" --no-gaps
```

---

### All Options Reference

| Option                                  | Type                   | Description                        |
| --------------------------------------- | ---------------------- | ---------------------------------- |
| **View Configuration**            |                        |                                    |
| `--ts-view`                           | `SPACE/VIEW/VERSION` | Custom Time Series view            |
| `--asset-view`                        | `SPACE/VIEW/VERSION` | Custom Asset view                  |
| `--equipment-view`                    | `SPACE/VIEW/VERSION` | Custom Equipment view              |
| `--file-view`                         | `SPACE/VIEW/VERSION` | Custom File view                   |
| `--notification-view`                 | `SPACE/VIEW/VERSION` | Custom Notification view           |
| `--order-view`                        | `SPACE/VIEW/VERSION` | Custom Maintenance Order view      |
| `--annotation-view`                   | `SPACE/VIEW/VERSION` | Custom Annotation view             |
| `--3d-view`                           | `SPACE/VIEW/VERSION` | Custom 3D Object view              |
| **Performance / Feature Toggles** |                        |                                    |
| `--no-gaps`                           | flag                   | Skip slow gap analysis             |
| `--no-maintenance`                    | flag                   | Skip maintenance metrics           |
| `--no-annotations`                    | flag                   | Skip annotation metrics            |
| `--no-3d`                             | flag                   | Skip 3D metrics                    |
| `--no-files`                          | flag                   | Skip file metrics                  |
| **Instance Limits**               |                        |                                    |
| `--max-ts`                            | number                 | Max time series to process         |
| `--max-assets`                        | number                 | Max assets to process              |
| `--max-equipment`                     | number                 | Max equipment to process           |
| `--max-notifications`                 | number                 | Max notifications to process       |
| `--max-orders`                        | number                 | Max maintenance orders to process  |
| `--max-annotations`                   | number                 | Max annotations to process         |
| `--max-3d`                            | number                 | Max 3D objects to process          |
| `--max-files`                         | number                 | Max files to process               |
| **Caching**                       |                        |                                    |
| `--use-cache`                         | flag                   | Reuse previous metrics from CDF    |
| `--only <section>`                    | string                 | Only recompute specific section(s) |
| **Output**                        |                        |                                    |
| `--dry-run`                           | flag                   | Save locally, don't upload to CDF  |
| `--output-file`                       | path                   | Custom output file path            |
| `-v`, `--verbose`                   | flag                   | Enable verbose logging             |

---

### Custom Limits

```bash
# Process fewer instances (faster for testing)
python run_metrics.py --max-ts 10000 --max-assets 5000

# Process more instances
python run_metrics.py --max-ts 1000000 --max-assets 500000
```

### Disable Optional Metrics

```bash
# Skip maintenance metrics
python run_metrics.py --no-maintenance

# Skip 3D and file annotations
python run_metrics.py --no-3d --no-annotations

# Skip all optional metrics (fastest)
python run_metrics.py --no-maintenance --no-annotations --no-3d --no-files

# Skip slow gap analysis (significantly faster)
python run_metrics.py --no-gaps
```

### Custom View Configuration

By default, the script uses CDM views (`cdf_cdm/CogniteTimeSeries/v1`, etc.). You can override these to use your own data model views.

**Format:** `--<type>-view "space/view_id/version"`

```bash
# Use custom views for time series and assets
python run_metrics.py \
  --ts-view "rmdm/YourOrgTimeSeries/v1" \
  --asset-view "rmdm/YourOrgAsset/v1"

# Configure multiple custom views
python run_metrics.py \
  --ts-view "my_space/MyTimeSeries/v1" \
  --asset-view "my_space/MyAsset/v1" \
  --equipment-view "my_space/MyEquipment/v1" \
  --file-view "my_space/MyFile/v1"

# Available view flags:
#   --ts-view           Time Series view
#   --asset-view        Asset view
#   --equipment-view    Equipment view
#   --file-view         File view
#   --notification-view Notification view
#   --order-view        Maintenance Order view
#   --annotation-view   Annotation view
#   --3d-view           3D Object view
```

### Caching and Partial Recompute

When iterating on a specific data type, you can reuse cached results for other sections instead of recomputing everything.

```bash
# Only recompute assets, keep everything else from cache
python run_metrics.py --use-cache --only assets

# Recompute multiple sections
python run_metrics.py --use-cache --only assets --only equipment

# Recompute just time series (useful after data changes)
python run_metrics.py --use-cache --only ts --no-gaps

# Available sections for --only:
#   ts, assets, equipment, maintenance, annotations, 3d, files
```

**How it works:**

1. Downloads previous metrics file from CDF
2. Runs only the specified phases
3. Merges new results with cached data
4. Uploads the combined result

This is useful when:

- Testing changes to a specific data type
- Debugging issues with one metric category
- Refreshing stale data for one section

### Combining Multiple Options

All command-line options can be combined freely. Here are common combinations:

#### Custom Views + Performance Options

```bash
# Use custom views AND skip gap analysis (faster)
python run_metrics.py \
  --ts-view "rmdm/YourOrgTimeSeries/v1" \
  --asset-view "rmdm/YourOrgAsset/v1" \
  --no-gaps

# Custom views + skip multiple optional metrics
python run_metrics.py \
  --ts-view "my_space/MyTimeSeries/v1" \
  --asset-view "my_space/MyAsset/v1" \
  --equipment-view "my_space/MyEquipment/v1" \
  --no-gaps \
  --no-maintenance \
  --no-3d

# Full custom data model with all performance optimizations
python run_metrics.py \
  --ts-view "rmdm/OrgTimeSeries/v1" \
  --asset-view "rmdm/OrgAsset/v1" \
  --equipment-view "rmdm/OrgEquipment/v1" \
  --file-view "rmdm/OrgFile/v1" \
  --notification-view "rmdm/OrgNotification/v1" \
  --order-view "rmdm/OrgOrder/v1" \
  --no-gaps \
  --no-annotations \
  --max-ts 50000 \
  --max-assets 25000
```

#### Custom Views + Caching

```bash
# Recompute only assets with custom asset view
python run_metrics.py \
  --asset-view "my_space/MyAsset/v1" \
  --use-cache \
  --only assets

# Recompute time series with custom view, skip gaps
python run_metrics.py \
  --ts-view "my_space/MyTimeSeries/v1" \
  --use-cache \
  --only ts \
  --no-gaps

# Refresh multiple sections with custom views
python run_metrics.py \
  --ts-view "rmdm/OrgTimeSeries/v1" \
  --equipment-view "rmdm/OrgEquipment/v1" \
  --use-cache \
  --only ts \
  --only equipment \
  --no-gaps
```

#### Testing and Development

```bash
# Quick test with custom views (small dataset, no upload)
python run_metrics.py \
  --ts-view "my_space/MyTimeSeries/v1" \
  --asset-view "my_space/MyAsset/v1" \
  --max-ts 1000 \
  --max-assets 500 \
  --no-gaps \
  --no-maintenance \
  --dry-run \
  -v

# Fast iteration: test one section with verbose output
python run_metrics.py \
  --equipment-view "my_space/MyEquipment/v1" \
  --use-cache \
  --only equipment \
  --dry-run \
  -v

# Full pipeline test with limited data
python run_metrics.py \
  --ts-view "rmdm/OrgTimeSeries/v1" \
  --asset-view "rmdm/OrgAsset/v1" \
  --equipment-view "rmdm/OrgEquipment/v1" \
  --max-ts 5000 \
  --max-assets 2000 \
  --no-gaps \
  --dry-run
```

#### Production Runs

```bash
# Full production run with custom data model
python run_metrics.py \
  --ts-view "rmdm/OrgTimeSeries/v1" \
  --asset-view "rmdm/OrgAsset/v1" \
  --equipment-view "rmdm/OrgEquipment/v1" \
  --file-view "rmdm/OrgFile/v1" \
  --notification-view "rmdm/OrgNotification/v1" \
  --order-view "rmdm/OrgOrder/v1" \
  --annotation-view "rmdm/OrgAnnotation/v1" \
  --3d-view "rmdm/Org3DObject/v1"

# Production run skipping slow operations
python run_metrics.py \
  --ts-view "rmdm/OrgTimeSeries/v1" \
  --asset-view "rmdm/OrgAsset/v1" \
  --equipment-view "rmdm/OrgEquipment/v1" \
  --no-gaps \
  --max-ts 500000 \
  --max-assets 200000

# Incremental update: refresh only changed sections
python run_metrics.py \
  --ts-view "rmdm/OrgTimeSeries/v1" \
  --use-cache \
  --only ts \
  --only assets
```

#### Quick Reference: Option Categories

| Category              | Options                                                                                                                                                 | Can Combine With |
| --------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------- |
| **Views**       | `--ts-view`, `--asset-view`, `--equipment-view`, `--file-view`, `--notification-view`, `--order-view`, `--annotation-view`, `--3d-view` | All options      |
| **Performance** | `--no-gaps`, `--no-maintenance`, `--no-3d`, `--no-annotations`, `--no-files`                                                                  | All options      |
| **Limits**      | `--max-ts`, `--max-assets`, `--max-equipment`, `--max-notifications`, `--max-orders`, `--max-annotations`, `--max-3d`, `--max-files`    | All options      |
| **Caching**     | `--use-cache`, `--only <section>`                                                                                                                   | All options      |
| **Output**      | `--dry-run`, `--output-file`, `-v`                                                                                                                | All options      |

---

### Common Questions (FAQ)

**Q: How do I use `--no-gaps` AND define custom views?**

```bash
python run_metrics.py --no-gaps --ts-view "my_space/MyTS/v1" --asset-view "my_space/MyAsset/v1"
```

**Q: How do I combine multiple `--no-*` flags with custom views?**

```bash
python run_metrics.py \
  --ts-view "rmdm/OrgTS/v1" \
  --asset-view "rmdm/OrgAsset/v1" \
  --no-gaps \
  --no-maintenance \
  --no-3d \
  --no-files
```

**Q: How do I set limits AND use custom views AND skip features?**

```bash
python run_metrics.py \
  --ts-view "my_space/MyTS/v1" \
  --asset-view "my_space/MyAsset/v1" \
  --max-ts 10000 \
  --max-assets 5000 \
  --no-gaps \
  --no-maintenance
```

**Q: How do I use caching with custom views?**

```bash
# Recompute only time series using custom view, reuse cached results for everything else
python run_metrics.py \
  --ts-view "my_space/MyTS/v1" \
  --use-cache \
  --only ts
```

**Q: How do I run a quick test with all optimizations?**

```bash
python run_metrics.py \
  --ts-view "my_space/MyTS/v1" \
  --asset-view "my_space/MyAsset/v1" \
  --max-ts 1000 \
  --max-assets 500 \
  --no-gaps \
  --no-maintenance \
  --no-3d \
  --no-annotations \
  --no-files \
  --dry-run \
  -v
```

**Q: How do I use multiple `--only` flags together?**

```bash
# Recompute both ts and assets, keep everything else from cache
python run_metrics.py --use-cache --only ts --only assets --only equipment
```

**Q: Can I specify a custom output file with other options?**

```bash
python run_metrics.py \
  --ts-view "my_space/MyTS/v1" \
  --no-gaps \
  --dry-run \
  --output-file "./my_custom_output.json"
```

**Q: What's the fastest possible run for testing?**

```bash
python run_metrics.py \
  --max-ts 100 \
  --max-assets 100 \
  --no-gaps \
  --no-maintenance \
  --no-3d \
  --no-annotations \
  --no-files \
  --dry-run
```

---

### Dry Run (Don't Upload)

```bash
# Save results locally instead of uploading to CDF
python run_metrics.py --dry-run

# Results saved to: scripts/metrics_output.json
```

### Verbose Logging

```bash
python run_metrics.py -v
```

## Output

The script produces:

1. **Console logs** - Progress updates during execution
2. **CDF File** - JSON metrics file uploaded to CDF (same format as Cognite Function)
3. **Local file** - (dry-run only) JSON file saved locally

The Streamlit dashboard can read the output file regardless of whether it was generated by the Cognite Function or this local script.

## Troubleshooting

### Authentication Errors

```
ValueError: COGNITE_PROJECT environment variable is required
```

- Set the `COGNITE_PROJECT` environment variable

```
Failed to authenticate: 401 Unauthorized
```

- Check your token is valid and not expired
- Verify you have access to the project

### Import Errors

```
ModuleNotFoundError: No module named 'metrics'
```

- Make sure you're running from the `scripts/` directory
- The script automatically adds the metrics module to the path

### Timeout/Memory Errors

If you run into memory issues with very large datasets:

- Use `--max-*` flags to limit the number of instances
- Process in smaller batches by running multiple times with different limits

## Architecture

```
scripts/
    client.py          # CDF authentication
    run_metrics.py     # Main script
    requirements.txt   # Dependencies
    README.md          # This file

functions/context_quality_handler/
    metrics/           # Shared processing modules (used by both)
        common.py
        timeseries.py
        asset_hierarchy.py
        equipment.py
        maintenance.py
        file_annotation.py
        model_3d.py
        files.py
        storage.py
```

The local script imports and reuses the same `metrics/` modules as the Cognite Function, ensuring consistent behavior.
